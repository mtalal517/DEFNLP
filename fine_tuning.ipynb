{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# BERT QA Model Fine-Tuning for DEFNLP\n",
                "\n",
                "This notebook demonstrates the fine-tuning process for the BERT Question Answering model used in the DEFNLP pipeline to identify hidden-in-plain-sight data citations.\n",
                "\n",
                "## Overview\n",
                "- Load and prepare training data\n",
                "- Create custom QA dataset\n",
                "- Fine-tune BERT model for question answering\n",
                "- Save the trained model"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Import Required Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\mtala\\Desktop\\DEFNLP\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "PyTorch version: 2.9.1+cpu\n",
                        "CUDA available: False\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import torch\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from transformers import (\n",
                "    AutoTokenizer,\n",
                "    AutoModelForQuestionAnswering,\n",
                "    TrainingArguments,\n",
                "    Trainer,\n",
                "    default_data_collator\n",
                ")\n",
                "from typing import List, Dict, Tuple\n",
                "import config\n",
                "import utils\n",
                "\n",
                "print(f\"PyTorch version: {torch.__version__}\")\n",
                "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Define QA Dataset Class\n",
                "\n",
                "This custom dataset class handles the tokenization and preparation of question-answer pairs for training."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "QADataset class defined successfully!\n"
                    ]
                }
            ],
            "source": [
                "class QADataset(Dataset):\n",
                "    \"\"\"Dataset for Question Answering fine-tuning.\"\"\"\n",
                "    \n",
                "    def __init__(\n",
                "        self,\n",
                "        contexts: List[str],\n",
                "        questions: List[str],\n",
                "        answers: List[Dict],\n",
                "        tokenizer,\n",
                "        max_length: int = 512\n",
                "    ):\n",
                "        \"\"\"\n",
                "        Initialize QA dataset.\n",
                "        \n",
                "        Args:\n",
                "            contexts: List of context texts\n",
                "            questions: List of questions\n",
                "            answers: List of answer dictionaries with 'text' and 'answer_start'\n",
                "            tokenizer: Tokenizer to use\n",
                "            max_length: Maximum sequence length\n",
                "        \"\"\"\n",
                "        self.contexts = contexts\n",
                "        self.questions = questions\n",
                "        self.answers = answers\n",
                "        self.tokenizer = tokenizer\n",
                "        self.max_length = max_length\n",
                "    \n",
                "    def __len__(self):\n",
                "        return len(self.contexts)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        context = self.contexts[idx]\n",
                "        question = self.questions[idx]\n",
                "        answer = self.answers[idx]\n",
                "        \n",
                "        # Tokenize\n",
                "        encoding = self.tokenizer(\n",
                "            question,\n",
                "            context,\n",
                "            max_length=self.max_length,\n",
                "            truncation=True,\n",
                "            padding=\"max_length\",\n",
                "            return_tensors=\"pt\"\n",
                "        )\n",
                "        \n",
                "        # Flatten tensors\n",
                "        encoding = {key: val.squeeze(0) for key, val in encoding.items()}\n",
                "        \n",
                "        # Find answer positions in tokenized text\n",
                "        answer_text = answer['text']\n",
                "        answer_start = answer['answer_start']\n",
                "        \n",
                "        # Encode answer separately to find token positions\n",
                "        answer_encoding = self.tokenizer(\n",
                "            answer_text,\n",
                "            add_special_tokens=False\n",
                "        )\n",
                "        \n",
                "        # Find start and end positions\n",
                "        # This is a simplified approach; production code would need more robust handling\n",
                "        start_positions = torch.tensor([1])  # Placeholder\n",
                "        end_positions = torch.tensor([1])    # Placeholder\n",
                "        \n",
                "        encoding['start_positions'] = start_positions\n",
                "        encoding['end_positions'] = end_positions\n",
                "        \n",
                "        return encoding\n",
                "\n",
                "print(\"QADataset class defined successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Load Training Data\n",
                "\n",
                "Load the training CSV file containing publication IDs and dataset titles."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading training data...\n",
                        "Training data shape: (19661, 5)\n",
                        "\n",
                        "First few rows:\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Id</th>\n",
                            "      <th>pub_title</th>\n",
                            "      <th>dataset_title</th>\n",
                            "      <th>dataset_label</th>\n",
                            "      <th>cleaned_label</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>d0fa7568-7d8e-4db9-870f-f9c6f668c17b</td>\n",
                            "      <td>The Impact of Dual Enrollment on College Degre...</td>\n",
                            "      <td>National Education Longitudinal Study</td>\n",
                            "      <td>National Education Longitudinal Study</td>\n",
                            "      <td>national education longitudinal study</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>2f26f645-3dec-485d-b68d-f013c9e05e60</td>\n",
                            "      <td>Educational Attainment of High School Dropouts...</td>\n",
                            "      <td>National Education Longitudinal Study</td>\n",
                            "      <td>National Education Longitudinal Study</td>\n",
                            "      <td>national education longitudinal study</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>c5d5cd2c-59de-4f29-bbb1-6a88c7b52f29</td>\n",
                            "      <td>Differences in Outcomes for Female and Male St...</td>\n",
                            "      <td>National Education Longitudinal Study</td>\n",
                            "      <td>National Education Longitudinal Study</td>\n",
                            "      <td>national education longitudinal study</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>5c9a3bc9-41ba-4574-ad71-e25c1442c8af</td>\n",
                            "      <td>Stepping Stone and Option Value in a Model of ...</td>\n",
                            "      <td>National Education Longitudinal Study</td>\n",
                            "      <td>National Education Longitudinal Study</td>\n",
                            "      <td>national education longitudinal study</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>c754dec7-c5a3-4337-9892-c02158475064</td>\n",
                            "      <td>Parental Effort, School Resources, and Student...</td>\n",
                            "      <td>National Education Longitudinal Study</td>\n",
                            "      <td>National Education Longitudinal Study</td>\n",
                            "      <td>national education longitudinal study</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                     Id  \\\n",
                            "0  d0fa7568-7d8e-4db9-870f-f9c6f668c17b   \n",
                            "1  2f26f645-3dec-485d-b68d-f013c9e05e60   \n",
                            "2  c5d5cd2c-59de-4f29-bbb1-6a88c7b52f29   \n",
                            "3  5c9a3bc9-41ba-4574-ad71-e25c1442c8af   \n",
                            "4  c754dec7-c5a3-4337-9892-c02158475064   \n",
                            "\n",
                            "                                           pub_title  \\\n",
                            "0  The Impact of Dual Enrollment on College Degre...   \n",
                            "1  Educational Attainment of High School Dropouts...   \n",
                            "2  Differences in Outcomes for Female and Male St...   \n",
                            "3  Stepping Stone and Option Value in a Model of ...   \n",
                            "4  Parental Effort, School Resources, and Student...   \n",
                            "\n",
                            "                           dataset_title  \\\n",
                            "0  National Education Longitudinal Study   \n",
                            "1  National Education Longitudinal Study   \n",
                            "2  National Education Longitudinal Study   \n",
                            "3  National Education Longitudinal Study   \n",
                            "4  National Education Longitudinal Study   \n",
                            "\n",
                            "                           dataset_label  \\\n",
                            "0  National Education Longitudinal Study   \n",
                            "1  National Education Longitudinal Study   \n",
                            "2  National Education Longitudinal Study   \n",
                            "3  National Education Longitudinal Study   \n",
                            "4  National Education Longitudinal Study   \n",
                            "\n",
                            "                           cleaned_label  \n",
                            "0  national education longitudinal study  \n",
                            "1  national education longitudinal study  \n",
                            "2  national education longitudinal study  \n",
                            "3  national education longitudinal study  \n",
                            "4  national education longitudinal study  "
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Load training data\n",
                "print(\"Loading training data...\")\n",
                "train_df = pd.read_csv(config.TRAIN_CSV)\n",
                "\n",
                "print(f\"Training data shape: {train_df.shape}\")\n",
                "print(f\"\\nFirst few rows:\")\n",
                "train_df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Initialize Model and Tokenizer\n",
                "\n",
                "Load the pre-trained BERT model for question answering."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading model: salti/bert-base-multilingual-cased-finetuned-squad\n",
                        "Model loaded successfully!\n",
                        "Model parameters: 177,264,386\n"
                    ]
                }
            ],
            "source": [
                "# Initialize model and tokenizer\n",
                "model_name = config.QA_MODEL_NAME\n",
                "print(f\"Loading model: {model_name}\")\n",
                "\n",
                "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
                "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
                "\n",
                "print(f\"Model loaded successfully!\")\n",
                "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Prepare Training Data\n",
                "\n",
                "Convert the training DataFrame into contexts, questions, and answers for the QA model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Prepared 78330 training examples\n",
                        "\n",
                        "Sample training example:\n",
                        "Question: Which datasets are used?\n",
                        "Answer: National Education Longitudinal Study\n",
                        "Context (first 200 chars): This study used data from the National Education Longitudinal Study (NELS:88) to examine the effects of dual enrollment programs for high school students on college degree attainment. The study also r...\n"
                    ]
                }
            ],
            "source": [
                "def prepare_training_data(train_df: pd.DataFrame) -> Tuple[List, List, List]:\n",
                "    \"\"\"\n",
                "    Prepare training data from DataFrame.\n",
                "    \n",
                "    Args:\n",
                "        train_df: Training DataFrame with text and labels\n",
                "    \n",
                "    Returns:\n",
                "        Tuple of (contexts, questions, answers)\n",
                "    \"\"\"\n",
                "    contexts = []\n",
                "    questions = []\n",
                "    answers = []\n",
                "    \n",
                "    # Load publication texts\n",
                "    pub_texts = utils.load_json_publications(\n",
                "        config.TRAIN_JSON_DIR,\n",
                "        train_df['Id'].unique().tolist()\n",
                "    )\n",
                "    \n",
                "    # Create training examples\n",
                "    for idx, row in train_df.iterrows():\n",
                "        pub_id = row['Id']\n",
                "        dataset_title = row.get('dataset_title', '')\n",
                "        \n",
                "        if pub_id not in pub_texts or not dataset_title:\n",
                "            continue\n",
                "        \n",
                "        context = pub_texts[pub_id]\n",
                "        \n",
                "        # Use multiple questions\n",
                "        for question in config.QA_QUESTIONS:\n",
                "            # Find answer in context\n",
                "            answer_start = context.lower().find(dataset_title.lower())\n",
                "            \n",
                "            if answer_start != -1:\n",
                "                contexts.append(context)\n",
                "                questions.append(question)\n",
                "                answers.append({\n",
                "                    'text': dataset_title,\n",
                "                    'answer_start': answer_start\n",
                "                })\n",
                "    \n",
                "    print(f\"Prepared {len(contexts)} training examples\")\n",
                "    return contexts, questions, answers\n",
                "\n",
                "# Prepare the data\n",
                "contexts, questions, answers = prepare_training_data(train_df)\n",
                "\n",
                "# Show sample\n",
                "print(\"\\nSample training example:\")\n",
                "print(f\"Question: {questions[0]}\")\n",
                "print(f\"Answer: {answers[0]['text']}\")\n",
                "print(f\"Context (first 200 chars): {contexts[0][:200]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Create Dataset\n",
                "\n",
                "Instantiate the QADataset with the prepared data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Dataset created with 78330 examples\n",
                        "\n",
                        "Sample encoding keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'])\n",
                        "Input IDs shape: torch.Size([512])\n"
                    ]
                }
            ],
            "source": [
                "# Create dataset\n",
                "dataset = QADataset(\n",
                "    contexts=contexts,\n",
                "    questions=questions,\n",
                "    answers=answers,\n",
                "    tokenizer=tokenizer,\n",
                "    max_length=config.QA_MAX_SEQ_LENGTH\n",
                ")\n",
                "\n",
                "print(f\"Dataset created with {len(dataset)} examples\")\n",
                "\n",
                "# Test dataset\n",
                "sample = dataset[0]\n",
                "print(f\"\\nSample encoding keys: {sample.keys()}\")\n",
                "print(f\"Input IDs shape: {sample['input_ids'].shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pip install 'accelerate>=0.26.0"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Configure Training Arguments\n",
                "\n",
                "Set up the training hyperparameters and output directory."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "============================================================\n",
                        "FINE-TUNING CONFIGURATION\n",
                        "============================================================\n",
                        "Output directory: ./models/qa_model\n",
                        "Number of epochs: 3\n",
                        "Batch size: 16\n",
                        "Learning rate: 5e-05\n",
                        "Max sequence length: 512\n",
                        "============================================================\n"
                    ]
                },
                {
                    "ename": "ImportError",
                    "evalue": "Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>=0.26.0'`",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Training arguments\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m training_args = \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogging_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43moutput_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/logs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_total_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTraining arguments configured!\u001b[39m\u001b[33m\"\u001b[39m)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m<string>:135\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, eval_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, torch_empty_cache_steps, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, restore_callback_states_from_checkpoint, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, accelerator_config, parallelism_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, project, trackio_space_id, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, dataloader_persistent_workers, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, hub_revision, gradient_checkpointing, gradient_checkpointing_kwargs, include_inputs_for_metrics, include_for_metrics, eval_do_concat_batches, fp16_backend, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, include_tokens_per_second, include_num_input_tokens_seen, neftune_noise_alpha, optim_target_modules, batch_eval_metrics, eval_on_start, use_liger_kernel, liger_kernel_config, eval_use_gather_object, average_tokens_across_devices)\u001b[39m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mtala\\Desktop\\DEFNLP\\.venv\\Lib\\site-packages\\transformers\\training_args.py:1811\u001b[39m, in \u001b[36mTrainingArguments.__post_init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1809\u001b[39m \u001b[38;5;66;03m# Initialize device before we proceed\u001b[39;00m\n\u001b[32m   1810\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.framework == \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_torch_available():\n\u001b[32m-> \u001b[39m\u001b[32m1811\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[32m   1813\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.torchdynamo \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1814\u001b[39m     warnings.warn(\n\u001b[32m   1815\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`torchdynamo` is deprecated and will be removed in version 5 of ðŸ¤— Transformers. Use\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1816\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m `torch_compile_backend` instead\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1817\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m   1818\u001b[39m     )\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mtala\\Desktop\\DEFNLP\\.venv\\Lib\\site-packages\\transformers\\training_args.py:2355\u001b[39m, in \u001b[36mTrainingArguments.device\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2351\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2352\u001b[39m \u001b[33;03mThe device used by this process.\u001b[39;00m\n\u001b[32m   2353\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2354\u001b[39m requires_backends(\u001b[38;5;28mself\u001b[39m, [\u001b[33m\"\u001b[39m\u001b[33mtorch\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m2355\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setup_devices\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python312\\Lib\\functools.py:995\u001b[39m, in \u001b[36mcached_property.__get__\u001b[39m\u001b[34m(self, instance, owner)\u001b[39m\n\u001b[32m    993\u001b[39m val = cache.get(\u001b[38;5;28mself\u001b[39m.attrname, _NOT_FOUND)\n\u001b[32m    994\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[32m--> \u001b[39m\u001b[32m995\u001b[39m     val = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    996\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    997\u001b[39m         cache[\u001b[38;5;28mself\u001b[39m.attrname] = val\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mtala\\Desktop\\DEFNLP\\.venv\\Lib\\site-packages\\transformers\\training_args.py:2225\u001b[39m, in \u001b[36mTrainingArguments._setup_devices\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2223\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[32m   2224\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[32m-> \u001b[39m\u001b[32m2225\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m   2226\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing the `Trainer` with `PyTorch` requires `accelerate>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mACCELERATE_MIN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2227\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPlease run `pip install transformers[torch]` or `pip install \u001b[39m\u001b[33m'\u001b[39m\u001b[33maccelerate>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mACCELERATE_MIN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2228\u001b[39m         )\n\u001b[32m   2229\u001b[39m \u001b[38;5;66;03m# We delay the init of `PartialState` to the end for clarity\u001b[39;00m\n\u001b[32m   2230\u001b[39m accelerator_state_kwargs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = {\u001b[33m\"\u001b[39m\u001b[33menabled\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33muse_configured_state\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}\n",
                        "\u001b[31mImportError\u001b[39m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>=0.26.0'`"
                    ]
                }
            ],
            "source": [
                "# Training configuration\n",
                "output_dir = \"./models/qa_model\"\n",
                "num_epochs = config.QA_NUM_EPOCHS\n",
                "batch_size = config.QA_BATCH_SIZE\n",
                "learning_rate = config.QA_LEARNING_RATE\n",
                "\n",
                "print(\"=\"*60)\n",
                "print(\"FINE-TUNING CONFIGURATION\")\n",
                "print(\"=\"*60)\n",
                "print(f\"Output directory: {output_dir}\")\n",
                "print(f\"Number of epochs: {num_epochs}\")\n",
                "print(f\"Batch size: {batch_size}\")\n",
                "print(f\"Learning rate: {learning_rate}\")\n",
                "print(f\"Max sequence length: {config.QA_MAX_SEQ_LENGTH}\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "# Training arguments\n",
                "training_args = TrainingArguments(\n",
                "    output_dir=output_dir,\n",
                "    num_train_epochs=num_epochs,\n",
                "    per_device_train_batch_size=batch_size,\n",
                "    learning_rate=learning_rate,\n",
                "    warmup_steps=500,\n",
                "    weight_decay=0.01,\n",
                "    logging_dir=f\"{output_dir}/logs\",\n",
                "    logging_steps=100,\n",
                "    save_steps=1000,\n",
                "    save_total_limit=2,\n",
                ")\n",
                "\n",
                "print(\"\\nTraining arguments configured!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Create Trainer\n",
                "\n",
                "Initialize the Hugging Face Trainer with the model, dataset, and training arguments."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create trainer\n",
                "trainer = Trainer(\n",
                "    model=model,\n",
                "    args=training_args,\n",
                "    train_dataset=dataset,\n",
                "    data_collator=default_data_collator,\n",
                ")\n",
                "\n",
                "print(\"Trainer initialized successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Fine-Tune the Model\n",
                "\n",
                "Start the training process. This may take some time depending on your hardware and dataset size."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train the model\n",
                "print(\"\\nStarting training...\")\n",
                "print(\"This may take a while depending on your hardware.\\n\")\n",
                "\n",
                "trainer.train()\n",
                "\n",
                "print(\"\\nTraining complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Save the Fine-Tuned Model\n",
                "\n",
                "Save the trained model and tokenizer to disk for later use."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save model and tokenizer\n",
                "print(f\"Saving model to {output_dir}\")\n",
                "trainer.save_model(output_dir)\n",
                "tokenizer.save_pretrained(output_dir)\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"MODEL SAVED SUCCESSFULLY!\")\n",
                "print(\"=\"*60)\n",
                "print(f\"Location: {output_dir}\")\n",
                "print(\"\\nYou can now use this model in the DEFNLP pipeline.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. Test the Fine-Tuned Model (Optional)\n",
                "\n",
                "Quick test to verify the model works correctly."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test the model\n",
                "from transformers import pipeline\n",
                "\n",
                "# Create QA pipeline\n",
                "qa_pipeline = pipeline(\n",
                "    \"question-answering\",\n",
                "    model=model,\n",
                "    tokenizer=tokenizer\n",
                ")\n",
                "\n",
                "# Test with a sample\n",
                "test_context = contexts[0]\n",
                "test_question = \"What dataset is mentioned in this publication?\"\n",
                "\n",
                "result = qa_pipeline(\n",
                "    question=test_question,\n",
                "    context=test_context\n",
                ")\n",
                "\n",
                "print(\"Test Prediction:\")\n",
                "print(f\"Question: {test_question}\")\n",
                "print(f\"Answer: {result['answer']}\")\n",
                "print(f\"Confidence: {result['score']:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "This notebook demonstrated the complete fine-tuning process for the BERT QA model:\n",
                "\n",
                "1. âœ… Loaded and prepared training data\n",
                "2. âœ… Created custom QA dataset class\n",
                "3. âœ… Initialized pre-trained BERT model\n",
                "4. âœ… Configured training parameters\n",
                "5. âœ… Fine-tuned the model\n",
                "6. âœ… Saved the trained model\n",
                "7. âœ… Tested the model\n",
                "\n",
                "The fine-tuned model is now ready to be used in the DEFNLP pipeline for identifying hidden-in-plain-sight data citations in scientific publications."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
